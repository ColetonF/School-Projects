# -*- coding: utf-8 -*-
"""MiniProject.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MIcmS4VItcGQQx82cCjbL3qnKRTwfE8y
"""

import os
import sys
import datetime
import collections

months = {
  "Jan": "01",
  "Feb": "02",
  "Mar": "03", 
  "Apr": "04",
  "May": "05",
  "Jun": "06", 
  "Jul": "07",
  "Aug": "08",
  "Sep": "09", 
  "Oct": "10",
  "Nov": "11",
  "Dec": "12",    
}

class LogAnalyzer:
  counter = collections.Counter()
  #data=Counter()
  #def __init__(self,name):
    #self.name=name

  def readFile(self,fileName):
    f = open(fileName,"r")
    return f.read()
  
  def gatherData(self):
    for fileName in os.listdir("/content"):
      if fileName.endswith(".log"): 
        self.parseData(self.readFile(fileName))
        continue
    #print(self.counter)

  def parseData(self,fileData):
    dictionary = dict()
    lines = fileData.split('"-"\n')
    count = 0
    for line in lines:

      dataBatch = line.replace('"', "").replace("[", "").split(' ')
      if len(dataBatch) >= 8:
        betterArray = [dataBatch[0], dataBatch[3], dataBatch[5], dataBatch[8]]

        #date parsing
        formattedDate = dataBatch[3].split("/")
        formattedDate[1] = months[formattedDate[1]]
        seperator = '-'
        betterArray[1] = seperator.join(formattedDate).split(':')[0]
        info = ", ".join(betterArray)
        
        self.counter.update({info: 1})


  def narrowByDate(self, minDate, maxDate, pool=counter):
    dateSpecificCounter = collections.Counter()
    for info in pool:
      dataArray = info.split(", ")
      dateOfLine = datetime.datetime.strptime(dataArray[1], "%d-%m-%Y")
      if minDate <= dateOfLine and maxDate >= dateOfLine:
        dateSpecificCounter.update({info: pool[info]})
    return dateSpecificCounter

  def narrowByStatus(self, statusCode, pool=counter):
    statusCounter = collections.Counter()
    for info in pool:
      status = info.split(", ")[3]
      if status == statusCode:
        statusCounter.update({info: pool[info]})
    return statusCounter

  def narrowByAction(self, HTTPAction, pool=counter):
    actionCounter = collections.Counter()
    for info in pool:
      action = info.split(", ")[2]
      if action == HTTPAction:
        actionCounter.update({info: pool[info]})
    return actionCounter

  def findTopNip(self, n, pool):
    ipCounter = collections.Counter()
    for line in pool:
      ip=line.split(", ")[0]
      ipCounter.update({ip: pool[line]})
    print(ipCounter.most_common(n))  #top N will be in the most common. 

  def findTopNActions(self, n, pool):
    actionCounter = collections.Counter()
    for line in pool:
      action=line.split(", ")[2]
      actionCounter.update({action: pool[line]})
    print(actionCounter.most_common(n))




anal = LogAnalyzer()
anal.gatherData()
pool=anal.narrowByDate(datetime.datetime(2016, 2, 18), datetime.datetime(2016, 3, 1))
print("\nTop 10 client IPs between 18/Feb/2016 and 01/Mar/2016")
anal.findTopNip(10, pool)
print("\nTop3 HTTP actions between 18/Feb/2016 and 01/Mar/2016")
anal.findTopNActions(3, pool)

#Top 5 client IPs w/ stat 404 b/t dates
print("\nTop5 client IPs with status code 404 between 18/Feb/2016 and 01/Mar/2016")
poolNarrowedByDate=anal.narrowByDate(datetime.datetime(2016, 2, 18), datetime.datetime(2016, 3, 1))
poolNarrowedByStatus = anal.narrowByStatus('404', poolNarrowedByDate)
anal.findTopNip(5, poolNarrowedByStatus)

#top 5 client IPs with status code 200 and HTTP action POST
print("\nTop5 client IPs with status code 200 and HTTP action POST between 18/Feb/2016 and 01/Mar/2016")
poolNarrowedByDate=anal.narrowByDate(datetime.datetime(2016, 2, 18), datetime.datetime(2016, 3, 1))
poolNarrowedByStatus = anal.narrowByStatus('200', poolNarrowedByDate)
poolNarrowedByAction = anal.narrowByAction('POST', poolNarrowedByStatus)
anal.findTopNip(5, poolNarrowedByAction)